import re, time, numpy as np, sounddevice as sd, os
from typing import Union

import transformers

SEED = 42
INTENT_LABEL = [
    "enquire_info",
    "retrieve",
    "enquire_location",
    "enquire_suitable_med",
    "general_chat",
    "set_furniture",
    "set_software"
]
# O: irelevant B: beginning I: inside
NER_LABEL = ["O", "B-ACE_Inhibitor", "I-ACE_Inhibitor", "B-Metformin", "I-Metformin", "B-Atorvastatin", "I-Atorvastatin", "B-Amitriptyline", "I-Amitriptyline",]

def check_NER(NER_Tag: Union[str, list[str]], fill_na=True) -> list[str]:
        """
        Convert detected tags into object list and store in cache if meet condition (receive)
        """
        
        if type(NER_Tag) == str:
            tag_list = list(NER_Tag)
        else:
            tag_list = NER_Tag
        
        detect_med = set()

        for token in tag_list:
            if token != "0" and NER_LABEL[int(token)][2:] != "":
                detect_med.add(NER_LABEL[int(token)][2:]) # [2:] -> remove the beginning and interim tag

        listed_med = list(detect_med)

        if fill_na:
            listed_med = listed_med + ["Empty"] * (4 - len(listed_med))

        return listed_med

def post_process_obj(output: list[dict]) -> list[4]:
    """
    Processing output list generated by NER Pipeline. Return a list of medicine lists
    """
    ner_tag = []
    for tkn in output:
        ner_tag.append(tkn["entity"][-1])
    detect_med = check_NER(ner_tag)
    return detect_med

def hybrid_split(string: str):
    regex = r"[\u4e00-\ufaff]|[0-9]+|[a-zA-Z]+\'*[a-z]*"
    matches = re.findall(regex, string, re.UNICODE)
    return matches

# Train script: legacy_codes/Intent_Prediction/Models.py
def load_asr_pipeline(repo="borisPMC/HouseHolder_WhisperSmall") -> transformers.Pipeline:
    if os.path.exists(f"./temp/{repo}"):
        asr_pipe = transformers.pipeline("automatic-speech-recognition", model=f"./temp/{repo}")
    else:
        print("Downloading ASR Model...")
        asr_pipe = transformers.pipeline("automatic-speech-recognition", model=repo)
        asr_pipe.save_pretrained(f"./temp/{repo}")
    return asr_pipe

# Train script: legacy_codes/Intent_Prediction/multitask_BERT_for_hf.py (joint trained under hard param sharing paradigm)
def load_med_list_pipeline(repo="borisPMC/HouseHolder_NER") -> transformers.Pipeline:
    if os.path.exists(f"./temp/{repo}"):
        med_list_pipe = transformers.pipeline("token-classification", model=f"./temp/{repo}")
    else:
        print("Downloading NER Model...")
        med_list_pipe = transformers.pipeline("token-classification", model=repo)
        med_list_pipe.save_pretrained(f"./temp/{repo}")
    return med_list_pipe

# Train script: legacy_codes/Intent_Prediction/multitask_BERT_for_hf.py (joint trained under hard param sharing paradigm)
def load_intent_pipeline(repo="borisPMC/HouseHolder_IC") -> transformers.Pipeline:
    if os.path.exists(f"./temp/{repo}"):
        intent_pipe = transformers.pipeline("text-classification", model=f"./temp/{repo}")
    else:
        print("Downloading Intent Model...")
        intent_pipe = transformers.pipeline("text-classification", model=repo)
        intent_pipe.save_pretrained(f"./temp/{repo}")
    return intent_pipe

def handle_intent(intent: str, tidied_obj_list):
    """
    Request Handler. Medicine Grabbing is supported at this version.
    """

    command = ""
    queued_obj = []
    msg = ""

    # The second printing line should be audio
    match intent:
        case "0": # "enquire_info"
            msg = "\nI would like to answer, but I know not much then you...\n"
        case "1": # "retrieve"
            if len(tidied_obj_list) > 0:
                msg = "\nGrabbing the requested items for you.\n"
                command = intent
                queued_obj = tidied_obj_list
            else:
                msg = "\nI can't retrieve any items if you aren't indicate an object!\n"
        case "2": # "enquire_location"
            msg = "\nI would like to answer, but I know not much about locations...\n"
        case "3": # "enquire_suitable_med"
            msg = "\nI would like to answer, but I know not much about medical diagnosis...\n"
        case "4": # "general_chat"
            msg = "\nHello, take care!\n"
        case "5": # "set_furniture",
            msg = "\nWait 'till I have legs to walk!\n",
        case "6": # "set_software"
            msg = "\nStill can't do Office works yet...\n"

    print(msg)
    return command, queued_obj

def listen_audio_thread(model_dict: dict, shared_dict: dict, listen_event) -> None:
    
    asr_pipe = model_dict["asr_pipe"]
    intent_pipe = model_dict["intent_pipe"]
    med_pipe = model_dict["med_list_pipe"]

    while True:

        listen_event.wait()

        audio_array = None
        transcript = None

        # print("\nRecording for 5 seconds...")
        audio_data = sd.rec(int(shared_dict["THREAD_PROCESS_TIMER"] * 16000), samplerate=16000, channels=1, dtype="float32")
        sd.wait()  # Wait until recording is finished
        audio_array = np.squeeze(audio_data)  # Convert to 1D array

        transcript = asr_pipe(audio_array)["text"]
        print("Transcript:", transcript)

        if len(transcript) > 0 :

            intent = intent_pipe(transcript)[0]["label"][-1]
            med_list = post_process_obj(med_pipe(transcript))
            # print(intent, med_list)

            tidied_obj_list = []
            for med in med_list:
                if med != "Empty":
                    tidied_obj_list.append(med)

            shared_dict["current_cmd"], shared_dict["queued_objects"] = handle_intent(intent, tidied_obj_list)

        else:
            print("No speech detected.")
        
        # Wait 1 second before looping again 
        time.sleep(1)

def live_test(model_dict):

    asr_pipe = model_dict["asr_pipe"]
    intent_pipe = model_dict["intent_pipe"]
    med_pipe = model_dict["med_list_pipe"]

    while True:

        audio_array = None
        transcript = None

        # print("\nRecording for 5 seconds...")
        audio_data = sd.rec(int(5 * 16000), samplerate=16000, channels=1, dtype="float32")
        sd.wait()  # Wait until recording is finished
        audio_array = np.squeeze(audio_data)  # Convert to 1D array

        transcript = asr_pipe(audio_array)["text"]
        # print("Transcript:", transcript)
        intent = -1
        tidied_obj_list = []

        valid_transcript = len(hybrid_split(transcript)) > 1

        if valid_transcript:

            intent = intent_pipe(transcript)[0]["label"][-1]
            med_list = post_process_obj(med_pipe(transcript))
            # print(intent, med_list)
            for med in med_list:
                if med != "Empty":
                    tidied_obj_list.append(med)
        
        intent_label = INTENT_LABEL[int(intent)] if valid_transcript else "None"

        print(f"Detected Medicines: {tidied_obj_list} | Intent: {intent_label}")