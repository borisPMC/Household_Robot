{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is for converting SLURP into Cantonese and upload to HF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\borisPMC\\Documents\\GitHub\\Medic_Grabber\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 11514/11514 [00:00<00:00, 18384.99 examples/s]\n",
      "Map: 100%|██████████| 2974/2974 [00:00<00:00, 17919.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Speech': 'play audiobook', 'Intent': 'play_audiobook', 'NER_Tag': \"'00\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from preprocessing import hybrid_split\n",
    "\n",
    "def getColsForTrain(example):\n",
    "\n",
    "    intent = example[\"intent\"]\n",
    "    speech = example[\"sentence\"]\n",
    "    tkn = [\"0\"] * len(hybrid_split(speech.lower()))\n",
    "    ner_tag = \"'\" + \"\".join(tkn)\n",
    "\n",
    "    result = {\n",
    "        \"Speech\": speech,\n",
    "        \"Intent\": intent,\n",
    "        \"NER_Tag\": ner_tag,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def import_jsonl(jsonl_path, train_data_file=\"train.jsonl\", test_data_file=\"test.jsonl\"):\n",
    "    \"\"\"Import a jsonl file and return a list of dictionaries.\"\"\"\n",
    "    ds_train = datasets.load_dataset(jsonl_path, data_files=train_data_file, split=\"train\")\n",
    "    filtered_train = datasets.Dataset.from_dict({\n",
    "        \"intent\": ds_train[\"intent\"],\n",
    "        \"sentence\": ds_train[\"sentence\"]\n",
    "    })\n",
    "    ds_test = datasets.load_dataset(jsonl_path, data_files=test_data_file, split=\"train\")\n",
    "    filter_test = datasets.Dataset.from_dict({\n",
    "        \"intent\": ds_test[\"intent\"],\n",
    "        \"sentence\": ds_test[\"sentence\"]\n",
    "    })\n",
    "    mapped_train = filtered_train.map(getColsForTrain, remove_columns=[\"sentence\", \"intent\"])\n",
    "    mapped_test = filter_test.map(getColsForTrain, remove_columns=[\"sentence\", \"intent\"])\n",
    "    ds = datasets.DatasetDict(\n",
    "        {\n",
    "            \"train\": mapped_train,\n",
    "            \"test\": mapped_test,\n",
    "        }\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "slurp_en = import_jsonl(\"training_data/slurp/\")\n",
    "\n",
    "print(slurp_en[\"train\"][36])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Count (Train Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [i[\"intent\"] for i in slurp_en[\"train\"]]\n",
    "label_list = set(list)\n",
    "label_count = [sum(1 for i in slurp_en[\"train\"] if i[\"intent\"] == label) for label in label_list]\n",
    "print(label_list)\n",
    "print(label_count)\n",
    "\n",
    "# {'quirky', 'alarm_query', 'iot_cleaning', 'music', 'lists_query', 'email_querycontact', 'post', 'query', 'alarm_remove', 'qa_currency', 'hue_lightup', 'iot_wemo_off', 'lists_remove', 'querycontact', 'general_greet', 'datetime_convert', 'sendemail', 'calendar_query', 'currency', 'email_sendemail', 'greet', 'social_query', 'podcasts', 'audio_volume_up', 'recommendation_movies', 'volume_other', 'cooking_query', 'calendar_set', 'convert', 'calendar_remove', 'remove', 'transport_query', 'cooking_recipe', 'definition', 'audio_volume_mute', 'audio_volume_down', 'factoid', 'qa_factoid', 'traffic', 'hue_lightdim', 'joke', 'play_music', 'events', 'createoradd', 'play_audiobook', 'qa_maths', 'play_podcasts', 'music_likeness', 'news_query', 'cleaning', 'audio_volume_other', 'lists_createoradd', 'alarm_set', 'qa_stock', 'general_joke', 'play_radio', 'transport_taxi', 'iot_hue_lightoff', 'wemo_off', 'transport_ticket', 'takeaway_order', 'recommendation_events', 'music_settings', 'takeaway_query', 'play_game', 'hue_lightoff', 'qa_definition', 'settings', 'recommendation_locations', 'transport_traffic', 'email_query', 'email_addcontact', 'iot_hue_lighton', 'iot_coffee', 'general_quirky', 'addcontact', 'set', 'coffee', 'iot_hue_lightchange', 'iot_hue_lightdim', 'game', 'radio', 'iot_hue_lightup', 'music_dislikeness', 'datetime_query', 'social_post', 'wemo_on', 'weather_query', 'music_query', 'iot_wemo_on', 'ticket'}\n",
    "# [9, 130, 92, 19, 197, 126, 4, 45, 78, 137, 2, 50, 162, 1, 23, 51, 7, 558, 5, 347, 2, 106, 4, 110, 70, 1, 4, 804, 1, 307, 7, 227, 207, 1, 110, 52, 9, 535, 2, 2, 2, 620, 1, 5, 150, 78, 189, 113, 500, 1, 17, 172, 182, 152, 70, 277, 100, 147, 2, 126, 135, 189, 50, 120, 108, 6, 266, 1, 173, 115, 415, 53, 22, 120, 546, 1, 6, 4, 125, 74, 4, 6, 74, 14, 342, 279, 1, 559, 150, 47, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m translation \u001b[38;5;129;01min\u001b[39;00m translations:\n\u001b[32m     10\u001b[39m             \u001b[38;5;28mprint\u001b[39m(translation.origin, \u001b[33m'\u001b[39m\u001b[33m -> \u001b[39m\u001b[33m'\u001b[39m, translation.text)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\asyncio\\runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from googletrans import Translator\n",
    "\n",
    "test_set = slurp_en[\"train\"][:10][\"Speech\"]\n",
    "\n",
    "async def translate_text():\n",
    "    async with Translator() as translator:\n",
    "        translations = await translator.translate(test_set, dest='Cantonese')\n",
    "        for translation in translations:\n",
    "            print(translation.origin, ' -> ', translation.text)\n",
    "\n",
    "asyncio.run(translate_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
